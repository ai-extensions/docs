{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI-Extension Application Hub - User Manual","text":""},{"location":"#purpose","title":"Purpose","text":"<p>The AI-Extensions project aims at supporting the Earth Science and Services Communities by expanding the existing Earth Observation (EO) platform offerings services with operationally mature AI/ML software capabilities. This is achieved through the AI-Extension Application Hub, a dedicated Cloud platform that provides the integration and operational implementation of EO and AI capabilities.  </p> <p>This User Manual provides a guideline, as well as step-by-step instructions, for developers and consumers to effectively leverage the AI-Extension Application Hub ML-Lab. </p>"},{"location":"#core-services","title":"Core Services","text":""},{"location":"#additional-apps","title":"Additional Apps","text":"<ul> <li>QGIS </li> <li>STAC</li> </ul>"},{"location":"#user-scenarios","title":"User Scenarios","text":""},{"location":"#user-showcases","title":"User Showcases","text":""},{"location":"#jupyterlab","title":"JupyterLab","text":"<p>JupyterLab is an interactive development environment that enables users to create and share documents that contain live code, visualisation and other content. With its flexible and extensible architecture, JupyterLab provides a seamless interface for data science workflows, allowing users to explore, analyze, and collaborate on data-driven projects effortlessly.  Link to the official documentation: https://jupyter.org/. </p> <p>After loading up, the JupyterLab dashboard will appear. </p> <p></p>"},{"location":"#code-server","title":"Code Server","text":"<p>Code Server enables the user to run Visual Studio Code (VS Code), a lightweight and versatile source code editor that combines the simplicity of a text editor with powerful developer tools, providing an intuitive and customizable environment for coding across various programming languages. With Code Server, VS Code and all its functionalities are available directly from the Application Hub server. Link to the official documentation: https://code.visualstudio.com/docs/remote/vscode-server. </p> <p>On the JupyterLab dashboard, click on the Code Server Logo.</p> <p></p> <p>The Code Server dashboard will appear.</p> <p></p> <p>You have access of all these functionalities from the vertical panel in the top-left corner of the dashboard: * Menu: access functions and settings within VS Code * Explore: navigate and manage files and directories in your workspace  * Search: find specific files, text, or symbols within your workspace * Source Control: manage version control system such as Git directly within VS Code * Run and Debug: execute and debug code with built-in tools * Extensions: enhance functionality by installing and managing extensions to support the development workflow  * Test: run tests and view test outptus </p>"},{"location":"#ml-flow","title":"ML-Flow","text":"<p><code>MLflow</code> is a powerful open-source platform that simplifies the end-to-end machine learning (ML) lifecycle management. It provides tools for tracking experiments, model hyperparameters, packaging code into reproducible runs, and sharing and deploying models across different environments seamlessly. <code>MLflow</code> enables users to effectively organize and monitor their ML projects, enabling collaboration, reproducibility, and streamlined deployment workflows. Link to the official documentation: https://mlflow.org/.</p> <p>On the JupyterLab dashboard, click on the <code>mlflow</code> Logo.</p> <p></p> <p>The <code>MLflow</code> dashboard will appear.</p> <p></p> <p>Below are a few examples of using <code>MLflow</code> in a ML project workflow: * The user can select one or multiple runs to Compare</p> <p></p> <ul> <li>The user can see a quick overview of each run and select which parameter(s) to analyse and plot on the graph</li> </ul> <p></p> <ul> <li>The user compares different parameteres fed to the CNN model</li> </ul> <p></p> <ul> <li>The user compares evaluation metrics of each run, to opt for the best model for his/her application. </li> </ul> <p></p>"},{"location":"#qgis","title":"QGIS","text":"<p>QGIS is a free and open-source application for viewing, editing, and analysing geo-spatial data. It provides a versatile platform equipped with tools for spatial analysis, geoprocessing, and map production, empowering users to make informed decisions based on geographic data. Link to the official documentation: https://qgis.org/it/site/. </p> <p>The QGIS-dedicated platform can be launched from the JupyterHub dashboard login page. When asked which Server Option to launch, select \"QGIS (includes tooling and plugings v0.4 aws)\" and then Start to launch it. </p> <p></p> <p>QGIS can then be launched by opening a terminal, typing <code>qgis</code> and executing it. The QGIS window will be displayed. </p>"},{"location":"#functionalities","title":"Functionalities","text":""},{"location":"#connection-to-stac-api","title":"Connection to STAC API","text":"<p>The SpatioTemporal Asset Catalog (STAC) is a powerful standard for describing geospatial data, so it can be more easily worked with, indexed, discovered and shared. Link to the official documentation: https://stacspec.org/en. </p> <p>The dedicated STAC Browser app can be launched at login with the option \"STAC Browser for AI-Extensions STAC API\".</p> <p></p> <p>After login, the STAC Browser dashboard will appear, showing the existing collections, which you can browse and visualise. </p> <p></p> <p>The dedicated STAC API endpoint can also be accessed via Jupyter Notebook by providing the appropriate authorisation <code>headers</code>. </p> <p><pre><code>payload = {\n    \"client_id\": \"ai-extensions\",\n    \"username\": \"ai-extensions-user\",\n    \"password\": os.environ.get(\"IAM_PASSWORD\"),\n    \"grant_type\": \"password\",\n}\n\ntoken = get_token(url=os.environ.get(\"IAM_URL\"), **payload)\ndel(payload)\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\ncat = Client.open(\"https://ai-extensions-stac.terradue.com\", headers=headers, ignore_conformance=True)\n</code></pre> To show the available collections in the Catalog. <pre><code>[c for c in cat.get_collections()]\n\n[&lt;CollectionClient id=ai-extensions-svv-dataset-labels&gt;,\n &lt;CollectionClient id=sentinel-s2-l2a-cogs&gt;,\n &lt;CollectionClient id=EUROSAT_2024_dataset&gt;,\n &lt;CollectionClient id=gisat-col&gt;]\n</code></pre></p>"},{"location":"#access-to-aws-s3","title":"Access to AWS s3","text":"<p>A dedicated Amazon S3 storage is pre-configured to be accessed from the App Hub. This can be done with the Amazon Web Server (AWS) <code>aws s3</code> commands in the AWS CLI.</p> <p>For example, to list the content of a specific S3 bucket, you can use the command below. <pre><code>aws s3 ls &lt;bucket_name&gt;\n</code></pre> Other examples with full syntax on using the <code>aws s3</code> command are described in the official AWS website.</p>"},{"location":"1-intro/1-foreword/","title":"Foreword","text":"<p>The AI-Extensions project aims at supporting the Earth Science and Services Communities by expanding the existing Earth Observation (EO) platform offerings services with operationally mature AI/ML software capabilities. This is achieved through the AI-Extension Application Hub (ML-Lab), a dedicated Cloud platform that provides the integration and operational implementation of EO and AI capabilities.  </p> <p>This User Manual provides a guideline, as well as step-by-step instructions, for developers and consumers to effectively leverage the AI-Extension Application Hub ML-Lab. </p>"},{"location":"1-intro/2-registration/","title":"Registration","text":"<p>Note: while being under development, the registration to the ML-Lab is for early-adopters users only, working and testing dedicated Showcases.</p>"},{"location":"1-intro/2-registration/#create-a-user-account","title":"Create a user account","text":"<ol> <li>Create an account and register on Terradue portal  your account https://www.terradue.com/portal/signup. Please note not to use special characters (including -, ., _, etc) for the username, but only just letters and numbers. </li> <li>Check your mailbox. We have sent you a confirmation email in order to validate your user email address. Click on the link to complete registration process.</li> </ol>"},{"location":"1-intro/2-registration/#notify-registered-account-to-terradue","title":"Notify registered account to Terradue","text":"<ol> <li>Notify Terradue (support@terradue.com) about successful registration, by providing your registered username.</li> </ol>"},{"location":"1-intro/2-registration/#dedicated-ml-lab-instance","title":"Dedicated ML-Lab instance","text":"<ol> <li>A dedicated ML-Lab instance will be created to your provided username</li> <li>You can access your ML-Lab via the provided URL (e.g. https://app-hub-ai-extensions-dev.terradue.com/</li> </ol>"},{"location":"2-core/1-intro/","title":"Application Hub ML-Lab","text":"<p>The Application Hub is a comprehensive and modular platform delivering Software-as-a-Service (SaaS) products, designed to cater to the diverse and multifaceted needs of the EO community. It is crafted to support a wide array of stakeholders, from developers and service providers integrating cutting-edge algorithms to researchers harnessing computational power, and analysts requiring clear and concise visualisations. At the heart of the Application Hub is the ability to manage the delivery of work environments and tools for a wide range of user tasks, such as develop, host, execute, and perform exploratory analysis of EO applications, all managed within a single, unified Cloud infrastructure.</p> <p>The Application Hub, leveraging Kubernetes and JupyterHub, creates a robust, scalable, and user-centric platform for EO applications and analytics. Kubernetes ensures scalable operation of containerized applications by managing deployment, operation, and traffic distribution, while JupyterHub orchestrates the launching, scaling, and management of application instances, acting as the primary gateway for user requests. The Hub uses dedicated namespaces for each application pod, ensuring organisation, security, and isolation. It also dynamically configures application pods based on the task, and personalises the experience based on user profiles through Kube Spawner. This design ensures the Application Hub remains modular, scalable, and capable of catering to the dynamic requirements of EO tasks.</p> <p>Typically, the Application Hub provides access to platforms and web apps in a SaaS mode. Users can engage with containerized Interactive Graphical Applications (IGAs), specialised geospatial data exploration web apps, and customizable dashboards. This allows users not only to explore and analyse results but also to execute new applications or analyses and customise their computing experiences, all accessed from the same integrated Hub interface. Ultimately, this enhances user experience, optimises software usage costs, and promotes ease of use, making it more accessible to the broader EO community.</p> <p>The Application Hub ML-Lab service leverages JupyterHub as an application hub to manage and deploy various web applications, including MLflow, JupyterLab, Code Server, QGIS Remote Desktop, and STAC Browser. JupyterHub acts as a central platform, facilitating the launching and management of these applications, providing a seamless and integrated experience for our users.</p> <p>By harnessing the Application Hub\u2019s capabilities, our service creates a unified and efficient environment where users can seamlessly switch between these web applications based on their specific needs. This integrated approach enhances productivity, collaboration, and the overall user experience, enabling our users to effectively utilise these applications to accomplish their goals.</p>"},{"location":"2-core/2-jupyterhub/","title":"JupyterHub","text":"<p>JupyterHub is a dedicated multi-user server that brings the power of JupyterLab to collaborative environments. It allows organizations to effortlessly deploy and manage Jupyter Notebook servers for multiple users, enabling seamless collaboration and resource sharing in data science and research settings. </p> <p>After login on your dedicated App Hub instance (e.g. https://app-hub-ai-extensions-dev.terradue.com/), you will be given the choice between different server options. These options are user-specific and depend on your registration profile settings. </p> <p>In the example shown below, seven server options are available: </p> <p></p> <p>JupyterHub acts as a central platform, facilitating the launching and management of applications, providing a seamless and integrated experience for our users. Various web applications such as MLflow, JupyterLab, Code Server are managed and deployed within JupyterHub, which can be launched by selecting either servers with <code>4GB RAM</code> and <code>12GB RAM</code> availability, below: </p> <ul> <li>Machine Learning Lab X.Y Small (4GB RAM)</li> <li>Machine Learning Lab X.Y Large (12GB RAM)</li> </ul> <p>Dedicated instances for other applications can be launched with their respective selection and then by clicking on <code>Start</code> to launch them.</p> <ul> <li>Machine Learning Lab X.Y Small - Argo Workflows (4GB RAM)</li> <li>Machine Learning Lab with GPU 0.10</li> <li>STAC Browseer Earth-Search AWS</li> <li>STAC Browseer for AI-Extensions STAC-API</li> <li>QGIS (includes tooling and plugins v0.4 aws)</li> </ul>"},{"location":"2-core/3-mlflow/","title":"MLflow","text":""},{"location":"2-core/3-mlflow/#introduction","title":"Introduction","text":"<p>The ML-Lab application integrates with MLflow, an open-source platform for managing the machine learning (ML) lifecycle. MLflow provides tools and functionalities to track experiments, package models, version models, model hyperparameters, packaging code into reproducible runs, deploy models, monitor performance, and enable collaboration among team members. MLflow enables users to effectively organize and monitor their ML projects, enabling collaboration, reproducibility, and streamlined deployment workflows.</p> <p>The following outlines the specific ways in which MLflow is used within the service:</p> <ul> <li>Experiment Tracking: The service utilises MLflow's experiment tracking capabilities to record parameters, metrics, and artefacts associated with each machine learning experiment. This enables reproducibility and facilitates comparison between different model configurations.</li> <li>Model Packaging: MLflow is used to package trained models in a standardised format. This includes saving the model artefacts, dependencies, and metadata required for deployment. The packaged models are self-contained and can be easily shared or deployed in various environments.</li> <li>Model Versioning: MLflow's versioning functionality is leveraged to manage different versions of trained models. This allows for tracking the evolution of models over time, comparing different versions, and ensuring reproducibility. It also facilitates collaboration among team members working on the same project.</li> <li>Integration with Existing Tools: MLflow integrates with popular machine learning tools and frameworks such as <code>TensorFlow</code>, <code>PyTorch</code>, and <code>scikit-learn</code>. This allows seamless integration of MLflow's tracking and management capabilities within the existing machine learning workflow, enhancing productivity and compatibility.</li> </ul> <p>By incorporating MLflow into the ML-Lab application, we ensure proper management, tracking, packaging, versioning, deployment, monitoring, and collaboration throughout the machine learning lifecycle. This enables efficient development, deployment, and maintenance of machine learning models within the service.</p>"},{"location":"2-core/3-mlflow/#starting-mlflow","title":"Starting MLflow","text":"<p>On the JupyterLab dashboard, click on the <code>mlflow</code> Logo.</p> <p></p> <p>The <code>MLflow</code> dashboard will appear.</p> <p></p>"},{"location":"2-core/3-mlflow/#practical-examples","title":"Practical Examples","text":"<p>Below are a few examples of using <code>MLflow</code> in a ML project workflow: * The user can select one or multiple runs to Compare</p> <p></p> <ul> <li>The user can see a quick overview of each run and select which parameter(s) to analyse and plot on the graph</li> </ul> <p></p> <ul> <li>The user compares different parameteres fed to the CNN model</li> </ul> <p></p> <ul> <li>The user compares evaluation metrics of each run, to opt for the best model for his/her application. </li> </ul> <p></p>"},{"location":"2-core/4-jupyterlab/","title":"JupyterLab","text":""},{"location":"2-core/4-jupyterlab/#introduction","title":"Introduction","text":"<p>JupyterLab, serves as a powerful and flexible web-based Integrated Development Environment (IDE) for data analysis, model development, and interactive scientific computing. With JupyterLab, our users can write and execute code, visualise data, and create rich, interactive notebooks, enabling efficient experimentation and exploration of their data. With its flexible and extensible architecture, JupyterLab provides a seamless interface for data science workflows, allowing AI-users to explore, analyze, and collaborate on data-driven projects effortlessly. </p> <p>JupyterLab provides a flexible and powerful environment that supports AI-users in the implementation of the User Scenarios, enabling efficient exploration, prototyping, and development of ML models. The following outlines the specific ways in which JupyterLab is used within the service:</p> <ul> <li>Interactive Data Analysis: JupyterLab enables AI-users to perform interactive data analysis using Python and other programming languages. They can write and execute code in Jupyter notebooks, visualise data, and generate insights. This allows her to explore and understand the training data, perform statistical analysis, and gain valuable insights into the underlying patterns and trends.</li> <li>Model Development and Training: AI-users can leverage JupyterLab's capabilities to build and train ML models. They can use popular ML libraries such as <code>TensorFlow</code>, <code>PyTorch</code>, or <code>scikit-learn</code> to develop and experiment with different models. JupyterLab's interactive nature allows for iterative model development, parameter tuning, and real-time monitoring of training progress.</li> <li>Data Visualization: JupyterLab provides powerful data visualisation tools, allowing AI-users to create rich and interactive visualisations of her data and model outputs. They can generate plots, charts, and graphs to analyse model performance, understand feature importance, and communicate results effectively.</li> <li>Code Reusability and Collaboration: JupyterLab supports code reusability and collaboration among team members. AI-users can organise her code into reusable functions or modules, making it easier to maintain and share across different projects. JupyterLab also facilitates collaborative work, allowing multiple team members to work on the same notebooks simultaneously, comment on code, and provide feedback.</li> <li>Documentation and Reporting: JupyterLab's notebook format provides a powerful means of documenting and reporting ML experiments. AI-users can combine code, visualisations, and narrative text in a single document, making it easier to communicate and share her work with stakeholders. Notebooks can be exported in various formats, such as HTML or PDF, for easy dissemination.</li> <li>Integration with Data Science Libraries: JupyterLab seamlessly integrates with a wide range of data science libraries and frameworks, providing access to a rich ecosystem of tools and resources. AI-users can leverage these libraries to perform tasks such as data preprocessing, feature engineering, model evaluation, and more, enhancing her productivity and enabling faster development cycles.</li> </ul> <p>By incorporating JupyterLab into the service, we empower AI-users with a versatile and user-friendly environment for data analysis, model development, visualisation, and collaboration. JupyterLab's interactive and flexible nature aligns perfectly with AI-users's scenarios, allowing her to leverage its capabilities to achieve her goals effectively.</p>"},{"location":"2-core/4-jupyterlab/#starting-jupyterlab","title":"Starting JupyterLab","text":"<p>After loading up, the JupyterLab dashboard will appear. </p> <p></p>"},{"location":"2-core/5-codeserver/","title":"Code Server","text":""},{"location":"2-core/5-codeserver/#introduction","title":"Introduction","text":"<p>Code Server enables users to run Visual Studio Code (VS Code), a lightweight and versatile source code editor that combines the simplicity of a text editor with powerful developer tools, providing an intuitive and customizable environment for coding across various programming languages. With Code Server, VS Code and all its functionalities are available directly from the Application Hub server. </p> <p>Code Server extends the capabilities of JupyterLab by providing a cloud-based IDE with GPU resources that enables efficient coding, collaboration, and development of ML models. It enables AI-users to build, train, and test ML models using popular frameworks like <code>PyTorch</code> or <code>TensorFlow</code>. The GPU support enhances model training performance, allowing for faster iterations and improved productivity.</p> <p>The following outlines the specific ways in which Code Server is used within the service:</p> <ul> <li>Development Environment: Code Server provides a cloud-based development environment that eliminates the need for local installations and configurations. AI-users can access Code Server through a web browser, enabling her to work from any device with an internet connection. This flexibility allows her to work remotely, collaborate with team members, and access her projects and codebase from anywhere.</li> <li>Code Editing and Collaboration: Code Server offers a powerful code editing experience with features like syntax highlighting, code completion, and code navigation. AI-users can write, edit, and debug code in various programming languages, including Python, R, or Julia. Code Server also supports collaboration features, allowing multiple users to edit and work on the same codebase simultaneously, enabling efficient teamwork and knowledge sharing.</li> <li>ML Model Development: AI-users can leverage Code Server to develop ML models efficiently. They can use popular ML frameworks and libraries like <code>TensorFlow</code>, <code>PyTorch</code>, or <code>scikit-learn</code> to build, train, and evaluate models. Code Server's integrated terminal allows her to execute commands and run experiments seamlessly.</li> <li>Git Integration: Code Server integrates with Git, a version control system, enabling AI-users to manage her codebase effectively. They can perform Git operations such as cloning repositories, creating branches, committing changes, and pushing code to remote repositories directly from within Code Server. This integration facilitates code versioning, collaboration, and easy synchronisation with code hosting platforms like GitHub or GitLab.</li> <li>Extension Ecosystem: Code Server provides an extension ecosystem that allows AI-users to customise and enhance her development environment. They can install extensions for additional functionalities, such as linting, code formatting, code snippets, or ML-specific tools. This extensibility ensures that AI-users can tailor her coding environment to meet her specific needs and preferences.</li> <li>Integrated Terminal: Code Server includes an integrated terminal, enabling AI-users to execute command-line operations without leaving the IDE. They can run scripts, install dependencies, manage virtual environments, and perform various system-level tasks directly within Code Server. This seamless integration streamlines her workflow and eliminates the need for switching between different tools.</li> </ul> <p>By incorporating Code Server into the service, we provide AI-users with a cloud-based IDE that supports her scenarios and enables efficient coding, collaboration, and ML model development. Code Server's accessibility, collaboration features, and integration with essential tools like Git make it an ideal choice for empowering AI-users to achieve her goals effectively.</p>"},{"location":"2-core/5-codeserver/#starting-code-server","title":"Starting Code Server","text":"<p>On the JupyterLab dashboard, click on the Code Server Logo.</p> <p></p> <p>The Code Server dashboard will appear.</p> <p></p> <p>You have access of all these functionalities from the vertical panel in the top-left corner of the dashboard: * Menu: access functions and settings within VS Code * Explore: navigate and manage files and directories in your workspace  * Search: find specific files, text, or symbols within your workspace * Source Control: manage version control system such as Git directly within VS Code * Run and Debug: execute and debug code with built-in tools * Extensions: enhance functionality by installing and managing extensions to support the development workflow  * Test: run tests and view test outptus </p>"},{"location":"2-core/6-aws/","title":"Access to Object Storage","text":""},{"location":"2-core/6-aws/#introduction","title":"Introduction","text":"<p>A dedicated object storage (in this example Amazon S3) is pre-configured to be accessed from the App Hub. This can be done with the Amazon Web Server (AWS) <code>aws s3</code> commands in the AWS CLI.</p>"},{"location":"2-core/6-aws/#practical-example","title":"Practical Example","text":"<p>For example, to list the content of a specific S3 bucket, you can use the command below. <pre><code>aws s3 ls &lt;bucket_name&gt;\n</code></pre> Other examples with full syntax on using the <code>aws s3</code> command are described in the official AWS website.</p>"},{"location":"3-plus/1-qgis/","title":"QGIS","text":""},{"location":"3-plus/1-qgis/#introduction","title":"Introduction","text":"<p>Our service incorporates QGIS Remote Desktop, managed by JupyterHub, providing a remote desktop environment with QGIS, a widely-used free and open-source application for viewing, editing, and analysing geo-spatial data. It provides a versatile platform equipped with tools to perform spatial analysis, geoprocessing, visualise geospatial data, enhancing their labelling and analysis tasks. This integration empowers AI-users to leverage QGIS's extensive capabilities directly from their web browser for making informed decisions based on geographic data.</p> <p>The following outlines the specific ways in which QGIS supports AI-users's labelling tasks within the service:</p> <ul> <li>Geospatial Data Exploration: QGIS allows AI-users to load and explore various types of geospatial data within the remote desktop environment. They can import satellite imagery, aerial photographs, vector data, and other geospatial datasets. QGIS provides a user-friendly interface to navigate and zoom in on specific areas of interest, enabling AI-users to closely examine the data they need to label.</li> <li>Labelling Tools and Annotations: QGIS offers a range of tools and functionalities specifically designed for labelling tasks. AI-users can leverage QGIS's labelling tools to create annotations such as points, lines, polygons, or complex geometries directly on the geospatial data. They can assign labels, attributes, or other relevant information to these annotations, facilitating the labelling process.</li> <li>Attribute Editing: QGIS allows AI-users to edit the attributes associated with geospatial features. This feature is particularly useful when labelling tasks involve updating or modifying existing attribute values. AI-users can easily access and edit attribute tables within QGIS, ensuring accurate and consistent labelling of geospatial data.</li> <li>Advanced Labelling Options: QGIS provides advanced labelling options to enhance the visual representation of labelled data. AI-users can configure labelling styles, such as font size, colour, and placement, to ensure readability and clarity of the labels. QGIS also supports labelling rules based on specific conditions or attribute values, allowing for automated labelling of geospatial features.</li> <li>Quality Control and Validation: QGIS offers tools for quality control and validation of labelled data. AI-users can use QGIS to review and verify the accuracy and consistency of labels by comparing them with reference data or applying predefined validation rules. This helps ensure the high quality of the labelled dataset.</li> <li>Integration with Existing Workflows: QGIS can be seamlessly integrated into AI-users's existing labelling workflows. They can import and export labelled data in various formats, making it compatible with other tools or systems. QGIS's flexibility allows AI-users to incorporate the labelled data generated within the remote desktop environment into her broader analysis pipelines or downstream applications.</li> </ul> <p>By leveraging QGIS in the remote desktop environment, AI-users gains access to a comprehensive labelling toolset specifically tailored for geospatial data. QGIS's geospatial data exploration capabilities, labelling tools, attribute editing features, advanced labelling options, quality control functionalities, and integration capabilities ensure efficient and accurate labelling tasks.</p>"},{"location":"3-plus/1-qgis/#starting-qgis","title":"Starting QGIS","text":"<p>The QGIS-dedicated platform can be launched from the JupyterHub dashboard login page. When asked which Server Option to launch, select \"QGIS (includes tooling and plugings v0.4 aws)\" and then Start to launch it. </p> <p></p> <p>QGIS can then be launched by opening a terminal, typing <code>qgis</code> and executing it. The QGIS window will be displayed.</p> <p></p>"},{"location":"3-plus/2-stac/","title":"STAC API","text":""},{"location":"3-plus/2-stac/#introduction","title":"Introduction","text":"<p>The SpatioTemporal Asset Catalog (STAC) is a powerful standard for describing geospatial data, so it can be more easily worked with, indexed, discovered and shared. As part of the Application Hub, the system integrates the STAC Browser, which allows AI-users to discover and explore EO data and training datasets. The STAC Browser supports easy search and retrieval of relevant EO data through the STAC standard, enabling efficient data discovery and selection for ML tasks.</p> <p>The STAC Browser enhances AI-users's workflows by providing a user-friendly interface for browsing and exploring the available EO data and training datasets. The following highlights the key features and benefits of using the STAC Browser to support AI-users scenarios:</p> <ul> <li>User-Friendly Data Exploration: The STAC Browser provides AI-users with an intuitive and user-friendly interface to explore and discover available EO data and training datasets. Through the browser's interface, AI-users can navigate through different catalog layers, filter data based on various criteria such as location, time range, and sensor type, and preview metadata associated with each dataset. This streamlines the process of finding relevant data for her specific tasks.</li> <li>Metadata Visualization and Exploration: The STAC Browser allows AI-users to visualise and explore metadata associated with EO data and training datasets. They can view essential information such as acquisition dates, sensor specifications, data formats, and available assets within each dataset. The browser may also provide interactive visualisations, such as maps or charts, to help AI-users gain insights into the spatial and temporal characteristics of the data.</li> <li>Advanced Search and Filtering: The STAC Browser supports advanced search and filtering capabilities, enabling AI-users to narrow down her search based on specific criteria. They can apply filters based on geographic extent, temporal range, data source, and other relevant metadata attributes. This helps AI-users quickly locate the data and training datasets that align with her specific needs, saving time and effort in the data discovery process.</li> <li>Dataset Previews and Samples: The STAC Browser allows AI-users to preview sample images or data subsets from the available datasets. This preview functionality gives her a glimpse of the data content, allowing her to assess the suitability of the datasets for her tasks. It enables quick visual inspection to verify if the data aligns with her requirements before proceeding with further processing or integration into her workflows.</li> <li>Integration with STAC and STAC API: The STAC Browser seamlessly integrates with the STAC standard and STAC API, providing a unified experience for data discovery. It leverages the underlying STAC metadata and data catalog structure to present a comprehensive view of available EO data and training datasets. The browser may interact with the STAC API to fetch the relevant metadata and facilitate efficient data access and retrieval.</li> </ul> <p>By incorporating a STAC Browser into the service, AI-users gain a powerful tool for EO data and training datasets discovery. The browser's user-friendly interface, advanced search capabilities, and metadata visualisation features simplify the process of finding and exploring relevant data. This enables AI-users to efficiently identify and select the data necessary for her training datasets and other ML workflows.</p>"},{"location":"3-plus/2-stac/#starting-stac-browser","title":"Starting STAC Browser","text":"<p>The dedicated STAC Browser app can be launched at login with the option \"STAC Browser for AI-Extensions STAC API\".</p> <p></p> <p>After login, the STAC Browser dashboard will appear, showing the existing collections, which you can browse and visualise. </p> <p></p>"},{"location":"3-plus/2-stac/#accessing-via-stac-api-endpoint","title":"Accessing via STAC API endpoint","text":"<p>The dedicated STAC API endpoint can also be accessed via Jupyter Notebook by providing the appropriate authorisation <code>headers</code>. </p> <p><pre><code>payload = {\n    \"client_id\": \"ai-extensions\",\n    \"username\": \"ai-extensions-user\",\n    \"password\": os.environ.get(\"IAM_PASSWORD\"),\n    \"grant_type\": \"password\",\n}\n\ntoken = get_token(url=os.environ.get(\"IAM_URL\"), **payload)\ndel(payload)\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\ncat = Client.open(\"https://ai-extensions-stac.terradue.com\", headers=headers, ignore_conformance=True)\n</code></pre> To show the available collections in the Catalog. <pre><code>[c for c in cat.get_collections()]\n\n[&lt;CollectionClient id=ai-extensions-svv-dataset-labels&gt;,\n &lt;CollectionClient id=sentinel-s2-l2a-cogs&gt;,\n &lt;CollectionClient id=EUROSAT_2024_dataset&gt;,\n &lt;CollectionClient id=gisat-col&gt;]\n</code></pre></p>"},{"location":"4-scenarios/scenario1/","title":"User Scenario 1 - Alice does Exploratory Data Analysis (EDA)","text":"<p>The purpose of Explaratory Data Analysis (EDA) is to analyse the data that will be used to train and evaluate Machine Learning models. In this Notebook are firstly shown the steps to access and visualize EO data (e.g. Sentinel-2 scenes) and their metadata using STAC API. Secondly, a pre-arranged DataFrame containing labeled geospatial data with reflectance values and vegetation indices is loaded and used for the purpose of EDA.</p> <p>The requirements defined in the User Scenario 1 are:</p> <ul> <li>Import Libraries for data manipulation (e.g. <code>pandas</code>), visualisation (e.g. <code>matplotlib</code>, <code>seaborn</code>), geospatial analysis (e.g <code>rasterio</code>).</li> <li>Connect to STAC API for accessing Sentinel-2 data and their metadata, as well as DataFrames that contain labelled geospatial data, using appropriate authentication credentials. Query and retrieving the Data using specific parameters to filter out retrieved data (e.g time range, spatial extent, cloud cover).</li> <li>Visualising data (eg. S-2 metadata, spectral bands) and charts / graphs of the analysed relevant information (e.g. with <code>matplotlib</code>, <code>seaborn</code>). These are useful for gaining information about the data and for performing other tasks such as band combination, cloud masking, etc.</li> <li>Perform analysis on the EO data labels to gain insights and understand patterns. This includes tasks such as calculating statistical summaries, generating histograms or scatter plots, as well as making correlation matrix for understanding relationships between variables.</li> <li>Document and share of results and findings of the EDA process by exporting charts and visualisation plots into a report.</li> </ul> <p>The link to the Notebook for User Scenario 1 is: https://github.com/ai-extensions/notebooks/blob/main/scenario-1/s1-eda.ipynb</p>"},{"location":"4-scenarios/scenario2/","title":"User Scenario 2 - Alice labels Earth Observation data","text":"<p>Labelling data is a crucial step in the process for developing supervised Machine Learning (ML) models. It involves the critical task of assigning relevant labels or categories to different features within the data, such as land cover class (e.g. vegetation, water bodies, urban area, etc.) or other physical characteristics of the Earth's surface. These labels can be binary (e.g., water or non-water) or multi-class (e.g., forest, grassland, urban).</p> <p>The requirements defined in the User Scenario 2 are:</p> <ul> <li>Import libraries for data manipulation (e.g. <code>pandas</code>), visualisation (e.g. <code>matplotlib</code>,<code>seaborn</code>), geospatial analysis (e.g <code>rasterio</code>).</li> <li>Create labelling layers, using e.g. QGIS or an interactive map based on <code>Leafmap</code>, by creating new vector layers or annotations to mark the labelled areas or features, and export them in formats suitable for further analysis or machine learning tasks, such as shapefiles, GeoJSON, or raster formats.</li> <li>Connect to STAC API for accessing to Sentinel-2 data, using appropriate authentication credentials.</li> <li>Query and retrieving the Data using specific parameters to filter out retrieved data (e.g time range, spatial extent, cloud cover).</li> <li>Validate the labelled data to ensure its accuracy and reliability, comparing it to a reference dataset.</li> <li>Use Labelled Data for Supervised Machine Learning to train models, evaluate their performance, and make predictions on new, unlabeled EO data.</li> </ul> <p>The link to the Notebook for User Scenario 2 is: \u200b\u200bhttps://github.com/ai-extensions/notebooks/blob/main/scenario-2/s2-labellingEOdata.ipynb</p>"},{"location":"4-scenarios/scenario3/","title":"User Scenario 3 - Alice describes the labelled Earth Observation data","text":"<p>Labeled Earth Observation (EO) data can be described using the SpatioTemporal Asset Catalog (STAC) standard. This allows to describe the labeled EO data while defining standardized sets of metadata to delineate its key properties, such as spatial and temporal extents, resolution, and other pertinent characteristics. Additionally, it enables the user to include details about the labeling process itself, as well as enabling specific parameters-driven queries on the catalog.</p> <p>The requirements defined in the User Scenario 3 are:</p> <ul> <li>Import libraries, including those for connecting to STAC API (e.g. <code>pystac</code>).</li> <li>Load labelled data (e.g. <code>.geojson</code> files).</li> <li>Create a STAC Item for each labelled EO data, including relevant metadata and STAC Extensions to describe the labelled data (e.g. the <code>stac-extensions/label extension</code> to provide detailed labelling information, or the <code>stac-extensions/asset</code> to associate assets or additional files with the labelled data).</li> <li>Extract metadata of the created STAC item, and show its relevant information, including visualisation on spatial map.</li> </ul> <p>The link to the Notebook for User Scenario 3 is: \u200b\u200bhttps://github.com/ai-extensions/notebooks/blob/main/scenario-3/s3-describingEOdata.ipynb.</p>"},{"location":"4-scenarios/scenario4/","title":"User Scenario 4 - Alice discovers labelled Earth Observation data","text":"<p>This Scenario documents the process for discovering labelled EO data described with the STAC standard. One of the notable advantages of the STAC-supported catalogs is the ability to filter search results using STAC metadata. This empowers the user to narrow down the search based on specific labeling criteria. By applying such filters, the user can pinpoint the datasets that align with the specific requirements.</p> <p>This Scenario explores two ways to discover, query and access labeled EO datasets: by using the STAC Browser, which provides a user-friendly graphical interface, or by using the STAC API endpoint, which enables the user to access to the STAC collection programmatically. </p> <p>The requirements defined in the User Scenario 4 are:</p> <ul> <li>Import Libraries (e.g. <code>pystac</code>).</li> <li>Understand about the STAC standard.</li> <li>Interact with a STAC Browser tool or the STAC API endpoint to access STAC data, by defining the search criteria based on the requirements (e.g. time range, geographic extent, etc.).</li> <li>Examine the search results to explore the available labeled EO datasets (view metadata summaries) and identify a dataset that meets the requirements to access associated assets.</li> <li>Depending on the access permissions and licensing, the user identifies labelled EO a dataset stored on AWS S3 bucket and is given the option to either download it or integrate it into the workflow for further analysis or model training.</li> </ul> <p>The link to the Notebook for User Scenario 4 is: \u200b\u200bhttps://github.com/ai-extensions/notebooks/blob/main/scenario-4/s4-discoveringLabelledEOData.ipynb.</p>"},{"location":"4-scenarios/scenario5/","title":"User Scenario 5 - Alice develops a new Machine Learning model","text":"<p>During the implementation of this Scenario, two Notebooks were developed:</p> <ul> <li>\u201cAlice develops a new machine learning\u201d Notebook: this is the main Notebook for Scenario 5, as it follows the requirements for Scenario 5 described in the Service Specification document. </li> <li>\u201cImplementation of EuroSAT STAC dataset\u201d Notebook: the objective of this Notebook was to generate STAC Catalog, Collection and Items of the EuroSAT dataset. The EuroSAT STAC dataset was then used as input dataset for developing and testing the main \u201cAlice develops a new machine learning\u201d Notebook. </li> </ul>"},{"location":"4-scenarios/scenario5/#notebook-for-alice-develops-a-new-machine-learning","title":"Notebook for \u201cAlice develops a new machine learning\u201d","text":"<p>The AI-user employs MLflow Tracking as a crucial tool throughout the ML model development cycle. It ensures effective log tracking and preserves vital information, including specific code versions, datasets used, and model hyperparameters. By logging this information, the reproducibility of the work drastically increases, enabling users to revisit and replicate past experiments accurately. Moreover, quality metrics have been tracked during the task, such as classification accuracy, loss function fluctuations, and inference time, enabling easy comparison between different models.</p> <p>A pivotal component of the platform is the Model Registry, which is seamlessly integrated with the experiment tracking functionality. The Model Registry acts as a central repository, allowing the user to manage and oversee their models effectively. This preservation of trained models is of significant economic importance, as training a model often requires substantial time and computing resources.</p> <p>The requirements defined in the User Scenario 5 that were included in this Notebook are:</p> <ul> <li>Import Libraries (e.g. <code>tensorflow</code>, <code>mlflow</code>, <code>sklearn</code>)</li> <li>Clarify the specific problem, identify the input data, and provide a pipeline for data ingestion. This ensures training a high-resolution classifier.</li> <li>Design the model architecture with the advantage of Convolutional Neural Networks (CNNs). The architecture may encompass different hidden layers with a variety of activation functions (such as ReLU, Sigmoid, tanh) and a couple of techniques that enhance the stability and reliability of the model, such as Batch Normalization and Regularization (namely Dropout).</li> <li>Train the model using the EuroSAT STAC training dataset and evaluate the performance of the trained model on the test dataset. </li> <li>Evaluate the ML model with evaluation metrics such as accuracy, precision, recall, F1 score, and the confusion matrix, in order to determine the model's effectiveness.</li> <li>Fine-tune the ML model by adjusting hyperparameters, modifying the architecture, or incorporating regularization techniques, as needed. This step may be repeated several times to reach the best performance and log the impact of each adjustment on the performance of the output model. </li> <li>Use MLflow Tracking tools (e.g. autolog functionality) to log relevant information such as hyperparameters, model configurations, training metrics, model weights, and evaluation results using MLflow APIs. </li> </ul> <p>The link to this Notebook is: \u200b\u200bhttps://github.com/ai-extensions/notebooks/blob/main/scenario-5/trials/s5-newMLModel.ipynb.</p>"},{"location":"4-scenarios/scenario5/#notebook-for-implementation-of-eurosat-dataset-stac","title":"Notebook for \u201cImplementation of EuroSAT dataset STAC\u201d","text":"<p>The EuroSAT dataset is based on ESA's Sentinel-2 data, covering 13 spectral bands and consisting out of 10 classes with a total of 27,000 labeled and geo-referenced images (https://github.com/phelber/EuroSAT). This Notebook was used to create a STAC Catalog, a STAC Collection, and STAC Items for the entire EuroSAT dataset. Each STAC Item was generated with three assets: the EuroSAT's georeferenced patches (in .tif format), their labels (in .geojson format), and their RGB-composite thumbnails (in .jpeg format). These STAC objects were posted into ESA-AI dedicated S3 bucket (s3://ai-ext-bucket-dev/), and subsequently posted on the ESA-AI dedicated STAC endpoint (https://ai-extensions-stac.terradue.com). </p> <p>The requirements that were included in this Notebook are:</p> <ul> <li>Import Libraries (e.g., <code>pystac</code>, <code>torchgeo</code>).</li> <li>Load the EuroSAT/EuroSAT100 Dataset using the torchgeo API. </li> <li>Generate STAC objects (STAC catalog, STAC collection, and STAC Item) with their corresponding characteristics, namely, id, properties, assets, STAC extensions, etc., using pystac standard conventions and place them in a .json file. The class label for each patch of data is stored in a <code>.geojson</code> file format.</li> <li>Post the generated STAC objects into the S3 bucket s3://ai-ext-bucket-dev.</li> <li>Publish all STAC items into the dedicated collection \u201cEUROSAT_2024_dataset\u201d in the STAC endpoint (https://ai-extensions-stac.terradue.com), and then validate by checking the published items.</li> </ul> <p>The link to the Notebook for User Scenario 5 is: https://github.com/ai-extensions/notebooks/blob/main/scenario-5-stac-dataloader/s5-stac-dataloder.ipynb. </p>"},{"location":"4-scenarios/scenario6/","title":"User Scenario 6 -","text":"<p>&lt; This has not been implemented yet, it's work in progress... &gt;</p>"}]}