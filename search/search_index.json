{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI-Extension Application Hub - User Manual","text":""},{"location":"#purpose","title":"Purpose","text":"<p>The AI-Extensions project aims at supporting the Earth Science and Services Communities by expanding the existing Earth Observation (EO) platform offerings services with operationally mature AI/ML software capabilities. This is achieved through the AI-Extension Application Hub, a dedicated Cloud platform that provides the integration and operational implementation of EO and AI capabilities.  </p> <p>This User Manual provides a guideline, as well as step-by-step instructions, for developers and consumers to effectively leverage the AI-Extension Application Hub ML-Lab. </p>"},{"location":"#core-services","title":"Core Services","text":""},{"location":"#additional-apps","title":"Additional Apps","text":"<ul> <li>QGIS </li> <li>STAC</li> </ul>"},{"location":"#user-scenarios","title":"User Scenarios","text":""},{"location":"#user-showcases","title":"User Showcases","text":""},{"location":"#jupyterlab","title":"JupyterLab","text":"<p>JupyterLab is an interactive development environment that enables users to create and share documents that contain live code, visualisation and other content. With its flexible and extensible architecture, JupyterLab provides a seamless interface for data science workflows, allowing users to explore, analyze, and collaborate on data-driven projects effortlessly.  Link to the official documentation: https://jupyter.org/. </p> <p>After loading up, the JupyterLab dashboard will appear. </p> <p></p>"},{"location":"#code-server","title":"Code Server","text":"<p>Code Server enables the user to run Visual Studio Code (VS Code), a lightweight and versatile source code editor that combines the simplicity of a text editor with powerful developer tools, providing an intuitive and customizable environment for coding across various programming languages. With Code Server, VS Code and all its functionalities are available directly from the Application Hub server. Link to the official documentation: https://code.visualstudio.com/docs/remote/vscode-server. </p> <p>On the JupyterLab dashboard, click on the Code Server Logo.</p> <p></p> <p>The Code Server dashboard will appear.</p> <p></p> <p>You have access of all these functionalities from the vertical panel in the top-left corner of the dashboard: * Menu: access functions and settings within VS Code * Explore: navigate and manage files and directories in your workspace  * Search: find specific files, text, or symbols within your workspace * Source Control: manage version control system such as Git directly within VS Code * Run and Debug: execute and debug code with built-in tools * Extensions: enhance functionality by installing and managing extensions to support the development workflow  * Test: run tests and view test outptus </p>"},{"location":"#ml-flow","title":"ML-Flow","text":"<p><code>MLflow</code> is a powerful open-source platform that simplifies the end-to-end machine learning (ML) lifecycle management. It provides tools for tracking experiments, model hyperparameters, packaging code into reproducible runs, and sharing and deploying models across different environments seamlessly. <code>MLflow</code> enables users to effectively organize and monitor their ML projects, enabling collaboration, reproducibility, and streamlined deployment workflows. Link to the official documentation: https://mlflow.org/.</p> <p>On the JupyterLab dashboard, click on the <code>mlflow</code> Logo.</p> <p></p> <p>The <code>MLflow</code> dashboard will appear.</p> <p></p> <p>Below are a few examples of using <code>MLflow</code> in a ML project workflow: * The user can select one or multiple runs to Compare</p> <p></p> <ul> <li>The user can see a quick overview of each run and select which parameter(s) to analyse and plot on the graph</li> </ul> <p></p> <ul> <li>The user compares different parameteres fed to the CNN model</li> </ul> <p></p> <ul> <li>The user compares evaluation metrics of each run, to opt for the best model for his/her application. </li> </ul> <p></p>"},{"location":"#qgis","title":"QGIS","text":"<p>QGIS is a free and open-source application for viewing, editing, and analysing geo-spatial data. It provides a versatile platform equipped with tools for spatial analysis, geoprocessing, and map production, empowering users to make informed decisions based on geographic data. Link to the official documentation: https://qgis.org/it/site/. </p> <p>The QGIS-dedicated platform can be launched from the JupyterHub dashboard login page. When asked which Server Option to launch, select \"QGIS (includes tooling and plugings v0.4 aws)\" and then Start to launch it. </p> <p></p> <p>QGIS can then be launched by opening a terminal, typing <code>qgis</code> and executing it. The QGIS window will be displayed. </p>"},{"location":"#functionalities","title":"Functionalities","text":""},{"location":"#connection-to-stac-api","title":"Connection to STAC API","text":"<p>The SpatioTemporal Asset Catalog (STAC) is a powerful standard for describing geospatial data, so it can be more easily worked with, indexed, discovered and shared. Link to the official documentation: https://stacspec.org/en. </p> <p>The dedicated STAC Browser app can be launched at login with the option \"STAC Browser for AI-Extensions STAC API\".</p> <p></p> <p>After login, the STAC Browser dashboard will appear, showing the existing collections, which you can browse and visualise. </p> <p></p> <p>The dedicated STAC API endpoint can also be accessed via Jupyter Notebook by providing the appropriate authorisation <code>headers</code>. </p> <p><pre><code>payload = {\n    \"client_id\": \"ai-extensions\",\n    \"username\": \"ai-extensions-user\",\n    \"password\": os.environ.get(\"IAM_PASSWORD\"),\n    \"grant_type\": \"password\",\n}\n\ntoken = get_token(url=os.environ.get(\"IAM_URL\"), **payload)\ndel(payload)\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\ncat = Client.open(\"https://ai-extensions-stac.terradue.com\", headers=headers, ignore_conformance=True)\n</code></pre> To show the available collections in the Catalog. <pre><code>[c for c in cat.get_collections()]\n\n[&lt;CollectionClient id=ai-extensions-svv-dataset-labels&gt;,\n &lt;CollectionClient id=sentinel-s2-l2a-cogs&gt;,\n &lt;CollectionClient id=EUROSAT_2024_dataset&gt;,\n &lt;CollectionClient id=gisat-col&gt;]\n</code></pre></p>"},{"location":"#access-to-aws-s3","title":"Access to AWS s3","text":"<p>A dedicated Amazon S3 storage is pre-configured to be accessed from the App Hub. This can be done with the Amazon Web Server (AWS) <code>aws s3</code> commands in the AWS CLI.</p> <p>For example, to list the content of a specific S3 bucket, you can use the command below. <pre><code>aws s3 ls &lt;bucket_name&gt;\n</code></pre> Other examples with full syntax on using the <code>aws s3</code> command are described in the official AWS website.</p>"},{"location":"core/aws/","title":"Access to object storage","text":"<p>A dedicated object storage (in this example Amazon S3) is pre-configured to be accessed from the App Hub. This can be done with the Amazon Web Server (AWS) <code>aws s3</code> commands in the AWS CLI.</p> <p>For example, to list the content of a specific S3 bucket, you can use the command below. <pre><code>aws s3 ls &lt;bucket_name&gt;\n</code></pre> Other examples with full syntax on using the <code>aws s3</code> command are described in the official AWS website.</p>"},{"location":"core/codeserver/","title":"Code Server","text":"<p>Code Server enables the user to run Visual Studio Code (VS Code), a lightweight and versatile source code editor that combines the simplicity of a text editor with powerful developer tools, providing an intuitive and customizable environment for coding across various programming languages. With Code Server, VS Code and all its functionalities are available directly from the Application Hub server. Link to the official documentation: https://code.visualstudio.com/docs/remote/vscode-server. </p> <p>On the JupyterLab dashboard, click on the Code Server Logo.</p> <p></p> <p>The Code Server dashboard will appear.</p> <p></p> <p>You have access of all these functionalities from the vertical panel in the top-left corner of the dashboard: * Menu: access functions and settings within VS Code * Explore: navigate and manage files and directories in your workspace  * Search: find specific files, text, or symbols within your workspace * Source Control: manage version control system such as Git directly within VS Code * Run and Debug: execute and debug code with built-in tools * Extensions: enhance functionality by installing and managing extensions to support the development workflow  * Test: run tests and view test outptus </p>"},{"location":"core/intro/","title":"Application Hub ML-Lab","text":"<p>The Application Hub is a comprehensive and modular platform delivering Software-as-a-Service (SaaS) products, designed to cater to the diverse and multifaceted needs of the EO community. It is crafted to support a wide array of stakeholders, from developers and service providers integrating cutting-edge algorithms to researchers harnessing computational power, and analysts requiring clear and concise visualisations. At the heart of the Application Hub is the ability to manage the delivery of work environments and tools for a wide range of user tasks, such as develop, host, execute, and perform exploratory analysis of EO applications, all managed within a single, unified Cloud infrastructure.</p> <p>The Application Hub, leveraging Kubernetes and JupyterHub, creates a robust, scalable, and user-centric platform for EO applications and analytics. Kubernetes ensures scalable operation of containerized applications by managing deployment, operation, and traffic distribution, while JupyterHub orchestrates the launching, scaling, and management of application instances, acting as the primary gateway for user requests. The Hub uses dedicated namespaces for each application pod, ensuring organisation, security, and isolation. It also dynamically configures application pods based on the task, and personalises the experience based on user profiles through Kube Spawner. This design ensures the Application Hub remains modular, scalable, and capable of catering to the dynamic requirements of EO tasks.</p> <p>Typically, the Application Hub provides access to platforms and web apps in a SaaS mode. Users can engage with containerized Interactive Graphical Applications (IGAs), specialised geospatial data exploration web apps, and customizable dashboards. This allows users not only to explore and analyse results but also to execute new applications or analyses and customise their computing experiences, all accessed from the same integrated Hub interface. Ultimately, this enhances user experience, optimises software usage costs, and promotes ease of use, making it more accessible to the broader EO community.</p> <p>The Application Hub ML-Lab service leverages JupyterHub as an application hub to manage and deploy various web applications, including MLflow, JupyterLab, Code Server, QGIS Remote Desktop, and STAC Browser. JupyterHub acts as a central platform, facilitating the launching and management of these applications, providing a seamless and integrated experience for our users.</p>"},{"location":"core/jupyterhub/","title":"JupyterHub","text":"<p>JupyterHub is a dedicated multi-user server that brings the power of JupyterLab to collaborative environments. It allows organizations to effortlessly deploy and manage Jupyter Notebook servers for multiple users, enabling seamless collaboration and resource sharing in data science and research settings. JupyterHub acts as a central platform, facilitating the launching and management of applications, providing a seamless and integrated experience for our users.</p> <p>After login on your dedicated App Hub instance (e.g. https://app-hub-ai-extensions-dev.terradue.com/), you will be given the choice between different server options. These options are user-specific and depend on your registration profile settings. </p> <p>In the example shown below, seven server options are available: </p> <p></p> <p>Various web applications such as MLflow, JupyterLab, Code Server are managed and deployed within JupyterHub, which can be launched with two options <code>4GB RAM</code> and <code>12GB RAM</code>, below:  * Machine Learning Lab 0.10 Large (4GB RAM) * Machine Learning Lab 0.10 Large (12GB RAM)</p> <p>various web applications, including , QGIS Remote Desktop, and STAC Browser. JupyterHub acts as a central platform, facilitating the launching and management of these applications, providing a seamless and integrated experience for our users.</p> <p>You can select one (e.g. \"Machine Learning Lab 0.10 Large (12GB RAM)\") and then click on <code>Start</code> to launch it. </p>"},{"location":"core/jupyterlab/","title":"JupyterLab","text":"<p>JupyterLab is an interactive development environment that enables users to create and share documents that contain live code, visualisation and other content. With its flexible and extensible architecture, JupyterLab provides a seamless interface for data science workflows, allowing users to explore, analyze, and collaborate on data-driven projects effortlessly.  Link to the official documentation: https://jupyter.org/. </p> <p>After loading up, the JupyterLab dashboard will appear. </p> <p></p>"},{"location":"core/mlflow/","title":"ML-Flow","text":"<p><code>MLflow</code> is a powerful open-source platform that simplifies the end-to-end machine learning (ML) lifecycle management. It provides tools for tracking experiments, model hyperparameters, packaging code into reproducible runs, and sharing and deploying models across different environments seamlessly. <code>MLflow</code> enables users to effectively organize and monitor their ML projects, enabling collaboration, reproducibility, and streamlined deployment workflows. Link to the official documentation: https://mlflow.org/.</p> <p>On the JupyterLab dashboard, click on the <code>mlflow</code> Logo.</p> <p></p> <p>The <code>MLflow</code> dashboard will appear.</p> <p></p> <p>Below are a few examples of using <code>MLflow</code> in a ML project workflow: * The user can select one or multiple runs to Compare</p> <p></p> <ul> <li>The user can see a quick overview of each run and select which parameter(s) to analyse and plot on the graph</li> </ul> <p></p> <ul> <li>The user compares different parameteres fed to the CNN model</li> </ul> <p></p> <ul> <li>The user compares evaluation metrics of each run, to opt for the best model for his/her application. </li> </ul> <p></p>"},{"location":"intro/foreword/","title":"Foreword","text":"<p>The AI-Extensions project aims at supporting the Earth Science and Services Communities by expanding the existing Earth Observation (EO) platform offerings services with operationally mature AI/ML software capabilities. This is achieved through the AI-Extension Application Hub (ML-Lab), a dedicated Cloud platform that provides the integration and operational implementation of EO and AI capabilities.  </p> <p>This User Manual provides a guideline, as well as step-by-step instructions, for developers and consumers to effectively leverage the AI-Extension Application Hub ML-Lab. </p>"},{"location":"intro/registration/","title":"Registration","text":"<p>Note: while being under development, the registration to the ML-Lab is for early-adopters users only, working and testing dedicated Showcases.</p>"},{"location":"intro/registration/#create-a-user-account","title":"Create a user account","text":"<ol> <li>Create an account and register on Terradue portal  your account https://www.terradue.com/portal/signup. Please note not to use special characters (including -, ., _, etc) for the username, but only just letters and numbers. </li> <li>Check your mailbox. We have sent you a confirmation email in order to validate your user email address. Click on the link to complete registration process.</li> </ol>"},{"location":"intro/registration/#notify-registered-account-to-terradue","title":"Notify registered account to Terradue","text":"<ol> <li>Notify Terradue (support@terradue.com) about successful registration, by providing your registered username.</li> </ol>"},{"location":"intro/registration/#dedicated-ml-lab-instance","title":"Dedicated ML-Lab instance","text":"<ol> <li>A dedicated ML-Lab instance will be created to your provided username</li> <li>You can access your ML-Lab via the provided URL (e.g. https://app-hub-ai-extensions-dev.terradue.com/</li> </ol>"},{"location":"plus/qgis/","title":"QGIS","text":"<p>QGIS is a free and open-source application for viewing, editing, and analysing geo-spatial data. It provides a versatile platform equipped with tools for spatial analysis, geoprocessing, and map production, empowering users to make informed decisions based on geographic data. Link to the official documentation: https://qgis.org/it/site/. </p> <p>The QGIS-dedicated platform can be launched from the JupyterHub dashboard login page. When asked which Server Option to launch, select \"QGIS (includes tooling and plugings v0.4 aws)\" and then Start to launch it. </p> <p></p> <p>QGIS can then be launched by opening a terminal, typing <code>qgis</code> and executing it. The QGIS window will be displayed.</p> <p></p>"},{"location":"plus/stac/","title":"STAC API","text":"<p>The SpatioTemporal Asset Catalog (STAC) is a powerful standard for describing geospatial data, so it can be more easily worked with, indexed, discovered and shared. Link to the official documentation: https://stacspec.org/en. </p> <p>The dedicated STAC Browser app can be launched at login with the option \"STAC Browser for AI-Extensions STAC API\".</p> <p></p> <p>After login, the STAC Browser dashboard will appear, showing the existing collections, which you can browse and visualise. </p> <p></p> <p>The dedicated STAC API endpoint can also be accessed via Jupyter Notebook by providing the appropriate authorisation <code>headers</code>. </p> <p><pre><code>payload = {\n    \"client_id\": \"ai-extensions\",\n    \"username\": \"ai-extensions-user\",\n    \"password\": os.environ.get(\"IAM_PASSWORD\"),\n    \"grant_type\": \"password\",\n}\n\ntoken = get_token(url=os.environ.get(\"IAM_URL\"), **payload)\ndel(payload)\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\ncat = Client.open(\"https://ai-extensions-stac.terradue.com\", headers=headers, ignore_conformance=True)\n</code></pre> To show the available collections in the Catalog. <pre><code>[c for c in cat.get_collections()]\n\n[&lt;CollectionClient id=ai-extensions-svv-dataset-labels&gt;,\n &lt;CollectionClient id=sentinel-s2-l2a-cogs&gt;,\n &lt;CollectionClient id=EUROSAT_2024_dataset&gt;,\n &lt;CollectionClient id=gisat-col&gt;]\n</code></pre></p>"},{"location":"scenarios/scenario1/","title":"User Scenario 1 - Alice does Exploratory Data Analysis (EDA)","text":"<p>The purpose of Explaratory Data Analysis (EDA) is to analyse the data that will be used to train and evaluate Machine Learning models. In this Notebook are firstly shown the steps to access and visualize EO data (e.g. Sentinel-2 scenes) and their metadata using STAC API. Secondly, a pre-arranged DataFrame containing labeled geospatial data with reflectance values and vegetation indices is loaded and used for the purpose of EDA.</p> <p>The requirements defined in the User Scenario 1 that were included in this Notebook are: * Import Libraries for data manipulation (e.g. <code>pandas</code>), visualisation (e.g. <code>matplotlib</code>, <code>seaborn</code>), geospatial analysis (e.g <code>rasterio</code>). * Connect to STAC API for accessing Sentinel-2 data and their metadata, as well as DataFrames that contain labelled geospatial data, using appropriate authentication credentials. Query and retrieving the Data using specific parameters to filter out retrieved data (e.g time range, spatial extent, cloud cover). * Visualising data (eg. S-2 metadata, spectral bands) and charts / graphs of the analysed relevant information (e.g. with <code>matplotlib</code>, <code>seaborn</code>). These are useful for gaining information about the data and for performing other tasks such as band combination, cloud masking, etc. * Perform analysis on the EO data labels to gain insights and understand patterns. This includes tasks such as calculating statistical summaries, generating histograms or scatter plots, as well as making correlation matrix for understanding relationships between variables. * Document and share of results and findings of the EDA process by exporting charts and visualisation plots into a report.</p> <p>The link to the Notebook for User Scenario 1 is: https://github.com/ai-extensions/notebooks/blob/main/scenario-1/s1-eda.ipynb</p>"},{"location":"scenarios/scenario2/","title":"User Scenario 2 - Alice labels Earth Observation data","text":"<p>Labelling data is a crucial step in the process for developing supervised Machine Learning (ML) models. It involves the critical task of assigning relevant labels or categories to different features within the data, such as land cover class (e.g. vegetation, water bodies, urban area, etc.) or other physical characteristics of the Earth's surface. These labels can be binary (e.g., water or non-water) or multi-class (e.g., forest, grassland, urban).</p> <p>The requirements defined in the User Scenario 2 that were included in this Notebook are: * Import libraries for data manipulation (e.g. <code>pandas</code>), visualisation (e.g. <code>matplotlib</code>,<code>seaborn</code>), geospatial analysis (e.g <code>rasterio</code>). * Create labelling layers, using e.g. QGIS or an interactive map based on <code>Leafmap</code>, by creating new vector layers or annotations to mark the labelled areas or features, and export them in formats suitable for further analysis or machine learning tasks, such as shapefiles, GeoJSON, or raster formats. * Connect to STAC API for accessing to Sentinel-2 data, using appropriate authentication credentials. * Query and retrieving the Data using specific parameters to filter out retrieved data (e.g time range, spatial extent, cloud cover). * Validate the labelled data to ensure its accuracy and reliability, comparing it to a reference dataset. * Use Labelled Data for Supervised Machine Learning to train models, evaluate their performance, and make predictions on new, unlabeled EO data.</p> <p>The link to the Notebook for User Scenario 2 is: \u200b\u200bhttps://github.com/ai-extensions/notebooks/blob/main/scenario-2/s2-labellingEOdata.ipynb</p>"}]}